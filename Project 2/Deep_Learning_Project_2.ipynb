{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONZ+SzU9zibquFlg4EFf59",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChrisKantor/Deep-Learning/blob/main/Project%202/Deep_Learning_Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Deep learning model that builds on the one made in HW3 for determining an infants pain level using vital signs\n",
        "#This improved model uses LSTM to better understand the sequential readings\n",
        "\n",
        "\n",
        "\n",
        "#Run these commands - NECCESARY to use the GPU\n",
        "# export CUDNN_PATH=$(dirname $(python -c \"import nvidia.cudnn;print(nvidia.cudnn.__file__)\"))\n",
        "# export LD_LIBRARY_PATH=${CUDNN_PATH}/lib\n",
        "\n",
        "#To connect to local runtime: jupyter lab --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0"
      ],
      "metadata": {
        "id": "-gD_j6_iqrxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aRuH-vPap5nA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6339a3c4-5f15-4294-bd7e-e93c1e877a09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-03-17 14:52:53.715962: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-03-17 14:52:54.771582: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "#import libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import PIL\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Some hyperparameter setup\n",
        "batch_size = 64           #set batch size to 64\n",
        "epochs = 20               #set num epochs to 20\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "dir = 'Deep Learning/Project 2/'\n",
        "data_dir = \"data/\"\n",
        "import os\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z45cpkBIsMQ-",
        "outputId": "2c11fd35-69f5-4ad5-aafc-5a06170036f9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "/home/ckantor/Deep Learning/Project 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "CrrDoReswut8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NEEDS FURTHER CLARIFICATION:\n",
        "#If a csv file sequence has an invalid row, do we just remove it or is the whole sequence invalid?\n",
        "#Can we mix the csv sequences together to get a fixed length input sequence? or should each seperate csv file be treated as its own sequence?\n",
        "#Are we predicting if the baby is in pain during the next timestep?\n",
        "\n",
        "\n",
        "\n",
        "#lots to do here - roughly follow this tutorial for general RNN processing: https://www.tensorflow.org/text/tutorials/text_generation\n",
        "\n",
        "#need sequences of data to use as input. Each csv file is 1 sequence, and each of them could potentially have missing/invalid data in them. 602 total csv files\n",
        "#Each csv file has 30 entries, but due to missing/invalid data, our cleaned sequences could have any number of entries\n",
        "#After cleaning the csv files, our dataset will be compromised of a bunch of variable length sequences\n",
        "#we will split our dataset up into training/validation sets on a sequence level\n",
        "\n",
        "#the inputs at a specific timestep will be the 3 labels in the csv files (Heart Rate, Respiratory Rate, O2 level) and the output will be (either if the baby is in pain OR if the baby is in pain during the NEXT step)? -Need clarification here\n"
      ],
      "metadata": {
        "id": "5wsgp_xGwyhP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "#use the os library to iterate through all files in the current path\n",
        "for (root,dirs,files) in os.walk(data_dir, topdown=True):\n",
        "  #open each CSV file, we don't want to open any other type of file\n",
        "  for f in files:\n",
        "    if f.endswith(\".csv\"):\n",
        "      count += 1\n",
        "\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0brwvTJ5rkZ",
        "outputId": "d82531a1-f7da-4fcf-8a9b-35c0cb3cd4bd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Setup"
      ],
      "metadata": {
        "id": "upaZTSH3w0qs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CClHL9t2w3kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "G1Fi-MTs5vzo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X0_nUOY_50Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Script"
      ],
      "metadata": {
        "id": "AVq8bgK550VC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8M7ZIwNM53As"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}