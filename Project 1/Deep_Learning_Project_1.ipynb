{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNju5KsyUNRAoLUv97bsiE5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChrisKantor/Deep-Learning/blob/main/Project%201/Deep_Learning_Project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WurbrvPdutvZ"
      },
      "outputs": [],
      "source": [
        "#Deep Learning model that can identify the state of different cooking ingredients\n",
        "\n",
        "#submit accuracy/loss figures for each epoch for both training and validation data\n",
        "\n",
        "#https://www.tensorflow.org/tutorials/images/classification\n",
        "\n",
        "#focus on getting a working model for pt 2. try a simple one first, then gradually increase complexity until we acheive overfitting. submit accuracy/loss figures for this part\n",
        "#pt3 is all about hyperparameter tuning/data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data"
      ],
      "metadata": {
        "id": "5mg9v0md9ixV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "## Mount Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/Deep Learning/Project 1/data/'"
      ],
      "metadata": {
        "id": "hZcioqNn9oyg",
        "outputId": "c7e1e6cf-21eb-4246-f143-e66491134fa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Some hyperparameter setup\n",
        "image_size = (256, 256)\n",
        "batch_size = 32\n",
        "label_mode = 'categorical' #uses categorical_crossentropy , 'int' uses sparse_categorical_crossentropy"
      ],
      "metadata": {
        "id": "NU1aL_33Aq9f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load data set\n",
        "#Loading training dataset\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir + 'train/',\n",
        "    image_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    label_mode = label_mode,\n",
        "    seed = 8312001,\n",
        ")\n",
        "\n",
        "#Loading validation dataset\n",
        "valid_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir + 'valid/',\n",
        "    image_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    label_mode = label_mode,\n",
        "    seed = 8312001\n",
        ")"
      ],
      "metadata": {
        "id": "vCeicokJ_x1w",
        "outputId": "d84139c4-bee9-4807-8494-f0d66dfa610f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7213 files belonging to 11 classes.\n",
            "Found 1543 files belonging to 11 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Configuring dataset for performance\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "valid_ds = valid_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "d6SL46q2nDd5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Creating and Training"
      ],
      "metadata": {
        "id": "WtLN7YEYpraA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 11\n",
        "\n",
        "#use rescaling layer to normalize inputs.\n",
        "model = Sequential([\n",
        "  layers.Rescaling(1./255, input_shape=(image_size[0], image_size[1], 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "R8KzRTyspuXt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "CuxtLeYIqSSq",
        "outputId": "e8454953-4107-4df7-80e3-daecbf3310c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling (Rescaling)       (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 256, 256, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 128, 128, 16)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 64, 64, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 65536)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               8388736   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 11)                1419      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8413739 (32.10 MB)\n",
            "Trainable params: 8413739 (32.10 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=valid_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "6Uc9vs5GqYEB",
        "outputId": "cc64f7b4-aa75-44b4-fcec-257962b61160",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Pn6fzq-8qaNf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}