{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyW5vJ+3vPLStNOtxkJV+g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChrisKantor/Deep-Learning/blob/main/Homework%203/Deep_Learning_HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCY4N1ruqq5u"
      },
      "outputs": [],
      "source": [
        "#Deep Learning Assignment Notes:\n",
        "#Need to submite 3 things, training code, the trained model, and then a bunch of results.\n",
        "#need to try all of the things listed in q2\n",
        "#lots of tial and eror with the hyperparameter tuning\n",
        "\n",
        "#data set is about baby vitals for detecting baby pain\n",
        "#3 classes: no pain, mild pain, lots of pain\n",
        "#col 1 is heart rate\n",
        "#col 2 is respiratory rate\n",
        "#col 3 is oxygen saturation\n",
        "#Can merge all the csv files into 1 large one\n",
        "#randomize and then split into training/validation data\n",
        "\n",
        "#need to clean the data, invalid data could be in any column\n",
        "\n",
        "#need 5 HIDDEN layers, so 7 total with the input and output layers\n",
        "#We can choose any number of neurons per layer\n",
        "\n",
        "#70% accuracy is a good minimum\n",
        "\n",
        "#Submit the best model only, but save figures for the other models with hyperparameter tuning\n",
        "#the model is not enough, need to submit a script which loads the model and then runs the test dataset on it\n",
        "#the test data has 2 folders same format as training data, need to combine the data into 1 csv\n",
        "\n",
        "#the testing script can be on a seperate cell in the notebook\n",
        "\n",
        "#figures are for validation loss\n",
        "#don't need to combine hyperparameters, just do them without each other, should be 12 figures total for part 2\n",
        "#1 figure for part 1 (the best model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading Dataset**"
      ],
      "metadata": {
        "id": "qC0rRcFpQf42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import tensorflow as tf\n",
        "import csv\n",
        "import os\n",
        "\n",
        "\n",
        "## Mount Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/Deep Learning/Homework 3 Data/'\n",
        "\n",
        "#create a new csv file that will hold all of our valid data\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Deep Learning/Homework 3 Data/baby_data.csv\", 'w') as csvfile:\n",
        "  csvwriter = csv.writer(csvfile)\n",
        "  #use the os library to iterate through all files in the current path\n",
        "  for (root,dirs,files) in os.walk(data_dir, topdown=True):\n",
        "    #open each CSV file, we don't want to open any other type of file\n",
        "    for f in files:\n",
        "      if f.endswith(\".csv\"):\n",
        "        #in each file, go through each row and check if it is valid\n",
        "        with open(os.path.join(root, f), mode ='r') as csvFile:\n",
        "          csvData = csv.reader(csvFile)\n",
        "\n",
        "          #one way to tell if the data is invalid is if the label is NOT [0, 1, 2]. This means there was something wrong with one of the sensors at the time of capture\n",
        "          #another way is to check if the heart rate, respiratory rate, or o2 level is too low, in this case we check if it is <= 0. if so, there was something wrong with the sensor\n",
        "          for row in csvData:\n",
        "            try:\n",
        "              if row[4] in \"012\" and int(row[1]) > 0 and int(row[2]) > 0 and int(row[3]) > 0:   #data is valid, so add it to the main csv\n",
        "\n",
        "                #row[0] just stores the row # in the csv file, so it is not needed in the training dataset\n",
        "                csvwriter.writerow([row[1], row[2], row[3], row[4]])\n",
        "\n",
        "            except ValueError:\n",
        "              continue\n",
        "\n",
        "print(\"Done writing to main csv file\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWP_e1NDQorH",
        "outputId": "8c367306-8feb-469b-b1ef-3425d97d1beb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Done writing to main csv file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we have a csv file that has ALL of the valid data which we will use in training our model\n",
        "#The next step is to split the data into a training and validation set, using a 90/10 split\n",
        "\n"
      ],
      "metadata": {
        "id": "G6cnVUTKscGS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}